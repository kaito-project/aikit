#syntax=aikit:test
apiVersion: v1alpha1
debug: true
models:
  - name: llama-3-8b-instruct
    source: oci://registry.ollama.ai/library/llama3:8b
    promptTemplates:
      - name: chatMsg
        template: |
          <|start_header_id|>{{if eq .RoleName \"assistant\"}}assistant{{else if eq .RoleName \"system\"}}system{{else if eq .RoleName \"tool\"}}tool{{else if eq .RoleName \"user\"}}user{{end}}<|end_header_id|>

          {{ if .FunctionCall -}}
          Function call:
          {{ else if eq .RoleName \"tool\" -}}
          Function response:
          {{ end -}}
          {{ if .Content -}}
          {{.Content -}}
          {{ else if .FunctionCall -}}
          {{ toJson .FunctionCall -}}
          {{ end -}}
          <|eot_id|>
      - name: function
        template: |
          <|start_header_id|>system<|end_header_id|>

          You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags. You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools:
          <tools>
          {{range .Functions}}
          {'type': 'function', 'function': {'name': '{{.Name}}', 'description': '{{.Description}}', 'parameters': {{toJson .Parameters}} }}
          {{end}}
          </tools>
          Use the following pydantic model json schema for each tool call you will make:
          {'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}<|eot_id|><|start_header_id|>assistant<|end_header_id|>
          Function call:
      - name: chat
        template: |
          <|begin_of_text|>{{.Input }}
          <|start_header_id|>assistant<|end_header_id|>
      - name: completion
          {{.Input}}
config: |
  - name: llama-3-8b-instruct
    backend: llama
    parameters:
      model: llama3
    context_size: 8192
    template:
      chat_message: \"chatMsg\"
      function: \"function\"
      chat: \"chat\"
      completion: \"completion\"
    stopwords:
      - <|im_end|>
      - <dummy32000>
      - \"<|eot_id|>\"
      - <|end_of_text|>
