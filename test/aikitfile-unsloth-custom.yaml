#syntax=aikit:test
apiVersion: v1alpha1
debug: true
runtime: cuda
models:
  - name: custom
    source: model-q4_k_m.gguf
config: |
  - name: custom
    backend: llama
    parameters:
      model: model-q4_k_m.gguf
    context_size: 4096
    f16: true
    mmap: true
