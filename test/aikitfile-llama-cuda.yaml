#syntax=aikit:test
apiVersion: v1alpha1
debug: true
runtime: cuda
models:
  - name: llama-3-8b-instruct
    source: https://huggingface.co/NousResearch/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf
    sha256: "170c177e91ca68a07c730ad49dce9f63e96a4e6ead86c11ad6cfbc6066af6242"
    promptTemplates:
      - name: instruct
        template: |
          <|start_header_id|>{{if eq .RoleName \"assistant\"}}assistant{{else if eq .RoleName \"system\"}}system{{else if eq .RoleName \"user\"}}user{{end}}<|end_header_id|>{{if .Content}}{{.Content}}{{end}}<|eot_id|>
config: |
  - name: llama-3-8b-instruct
    backend: llama
    parameters:
      top_k: 80
      temperature: 0.2
      top_p: 0.7
      model: Meta-Llama-3-8B-Instruct-Q4_K_M.gguf
    context_size: 8192
    gpu_layers: 33
    f16: true
    batch: 512
    mmap: true
    template:
      chat_message: \"instruct\"
    stopwords:
    - <|start_header_id|>
    - <|end_header_id|>
    - <|eot_id|>
    - <|reserved_special_token
