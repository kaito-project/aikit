image:
  repository: ghcr.io/kaito-project/aikit/llama3
  tag: "8b"
  pullPolicy: IfNotPresent

replicaCount: 1

# LeaderWorkerSet configuration for distributed inference
leaderWorkerSet:
  enabled: false
  replicas: 1
  leaderWorkerTemplate:
    size: 3  # Total number of pods (1 leader + 2 workers)
    restartPolicy: RecreateGroupOnPodRestart

  # Leader configuration
  leader:
    # Use a wrapper image that can coordinate with LocalAI for distributed inference
    # If empty, uses the main image (which may not support distributed coordination)
    image:
      repository: ""  # e.g., "ghcr.io/sozercan/aikit-leader"
      tag: ""  # If empty, uses the main image tag
      pullPolicy: ""  # If empty, uses the main image pullPolicy
    resources: {}
    securityContext: {}
    args: []
    command: []
    env:
      # Standard LWS environment variables for coordination
      - name: LWS_GROUP_SIZE
        valueFrom:
          fieldRef:
            fieldPath: metadata.annotations['leaderworkerset.sigs.k8s.io/group-size']
      - name: LWS_LEADER_ADDRESS
        valueFrom:
          fieldRef:
            fieldPath: metadata.annotations['leaderworkerset.sigs.k8s.io/leader-address']

  # Worker configuration
  worker:
    # Use a worker image that can connect to the leader for distributed compute
    # If empty, uses the main image (which may not support worker coordination)
    image:
      repository: ""  # e.g., "ghcr.io/sozercan/aikit-worker"
      tag: "latest"
      pullPolicy: IfNotPresent
    resources: {}
    securityContext: {}
    args: []
    command: []
    env:
      # Worker-specific environment variables
      - name: LWS_GROUP_SIZE
        valueFrom:
          fieldRef:
            fieldPath: metadata.annotations['leaderworkerset.sigs.k8s.io/group-size']

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""
podAnnotations: {}
podLabels: {}

podSecurityContext:
  fsGroup: 999
  supplementalGroups:
    - 999

securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop:
    - ALL
  readOnlyRootFilesystem: false # aikit extracts backends during runtime
  runAsGroup: 999
  runAsNonRoot: true
  runAsUser: 1000

service:
  type: ClusterIP
  port: 8080

resources:
  limits:
    memory: 8Gi
    # nvidia.com/gpu: "1"
  requests:
    cpu: 100m
    memory: 128Mi
    # nvidia.com/gpu: "1"

livenessProbe:
  httpGet:
    path: /
    port: http
readinessProbe:
  httpGet:
    path: /
    port: http

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

nodeSelector: {}

affinity: {}

rbac:
  create: true

enableRuntimeDefaultSeccompProfile: true
postInstall:
  resources: {}
  affinity: {}
  tolerations: []
  nodeSelector: {kubernetes.io/os: linux}
  securityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
    runAsGroup: 999
    runAsNonRoot: true
    runAsUser: 1000
  labelNamespace:
    enabled: true
    image:
      repository: registry.k8s.io/kubectl
      tag: v1.33.3
      pullPolicy: IfNotPresent
      pullSecrets: []
    podSecurity: ["pod-security.kubernetes.io/audit=restricted",
      "pod-security.kubernetes.io/audit-version=latest",
      "pod-security.kubernetes.io/warn=restricted",
      "pod-security.kubernetes.io/warn-version=latest",
      "pod-security.kubernetes.io/enforce=restricted",
      "pod-security.kubernetes.io/enforce-version=v1.30"]
    extraAnnotations: {}
    extraRules: []
    priorityClassName: ""
