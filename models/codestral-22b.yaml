#syntax=ghcr.io/sozercan/aikit:latest
apiVersion: v1alpha1
debug: true
runtime: cuda
models:
  - name: codestral-22b
    source: https://huggingface.co/lmstudio-community/Codestral-22B-v0.1-GGUF/resolve/main/Codestral-22B-v0.1-Q4_K_M.gguf
    sha256: 003e48ed892850b80994fcddca2bd6b833b092a4ef2db2853c33a3144245e06c
    promptTemplates:
      - name: instruct
        template: |
          [INST]{{ if .SystemPrompt }}{{ .SystemPrompt }}{{ end }} {{ .Input }}[/INST]
config: |
  - name: codestral-22b
    backend: llama
    parameters:
      model: Codestral-22B-v0.1-Q4_K_M.gguf
    context_size: 8192
    template:
      chat: instruct
      completion: instruct
    stopwords:
     - \"[INST]\"
     - \"[/INST]\"
     - \"[PREFIX]\"
     - \"[MIDDLE]\"
     - \"[SUFFIX]\"
    f16: true
    mmap: true
