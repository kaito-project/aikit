#syntax=ghcr.io/sozercan/aikit:latest
apiVersion: v1alpha1
debug: true
runtime: cuda
models:
  - name: mixtral-8x7b-instruct
    source: https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF/resolve/main/mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf
    sha256: 9193684683657e90707087bd1ed19fd0b277ab66358d19edeadc26d6fdec4f53
config: |
  - name: mixtral-8x7b-instruct
    backend: llama
    parameters:
      model: mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf
    context_size: 4096
    gpu_layers: 15
    f16: true
    mmap: true
