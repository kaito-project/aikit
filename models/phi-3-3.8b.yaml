#syntax=ghcr.io/sozercan/aikit:latest
apiVersion: v1alpha1
debug: true
runtime: cuda
models:
  - name: phi-3-3.8b
    source: https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf
    sha256: 8a83c7fb9049a9b2e92266fa7ad04933bb53aa1e85136b7b30f1b8000ff2edef
    promptTemplates:
      - name: chatMsg
        template: |
          <|{{ .RoleName }}|>
          {{.Content}}<|end|>
      - name: chat
        template: |
          {{.Input}}
          <|assistant|>
      - name: completion
        template: |
          {{.Input}}
config: |
  - name: phi-3-3.8b
    backend: llama
    parameters:
      model: Phi-3-mini-4k-instruct-q4.gguf
    context_size: 4096
    template:
      chat_message: chatMsg
      chat: chat
      completion: completion
    stopwords:
    - <|user|>
    - <|assistant|>
    - <|end|>
    - <|endoftext|>
    gpu_layers: 33
    f16: true
    mmap: true
