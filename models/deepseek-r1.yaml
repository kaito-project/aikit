#syntax=aikit:test
apiVersion: v1alpha1
debug: true
runtime: cuda
models:
  - name: DeepSeek-R1-UD-IQ1_S-00001-of-00003.gguf
    source: DeepSeek-R1-UD-IQ1_S-00001-of-00003.gguf
  - name: DeepSeek-R1-UD-IQ1_S-00002-of-00003.gguf
    source: DeepSeek-R1-UD-IQ1_S-00002-of-00003.gguf
  - name: DeepSeek-R1-UD-IQ1_S-00003-of-00003.gguf
    source: DeepSeek-R1-UD-IQ1_S-00003-of-00003.gguf
config: |
  - name: deepseek
    backend: llama
    parameters:
      model: DeepSeek-R1-UD-IQ1_S-00001-of-00003.gguf
    context_size: 131072
    mmap: true
    f16: true
    stopwords:
      - <｜begin▁of▁sentence｜>
      - <｜end▁of▁sentence｜>
      - <｜User｜>
      - <｜Assistant｜>
    template:
      chat_message: |
        {{if eq .RoleName "system" -}}{{.Content }}
        {{ end -}}
        {{if eq .RoleName "user" -}}<｜User｜>{{.Content}}
        {{end -}}
        {{if eq .RoleName "assistant" -}}<｜Assistant｜>{{.Content}}<｜end▁of▁sentence｜>{{end}}
      completion: |
        {{.Input}}
      chat: |
        {{.Input -}}<｜Assistant｜>
