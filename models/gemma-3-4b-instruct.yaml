#syntax=ghcr.io/kaito-project/aikit/aikit:latest
apiVersion: v1alpha1
debug: true
runtime: cuda
models:
  - name: gemma-3-4b-instruct
    source: https://huggingface.co/unsloth/gemma-3-4b-it-qat-GGUF/resolve/main/gemma-3-4b-it-qat-Q4_K_M.gguf
    sha256: 8b6cc3dc9e426d760a05aa0d53ebb66229ed8885fcc79f929837b520d2effcd9
config: |
  - name: gemma-3-4b-instruct
    backend: llama-cpp
    parameters:
      model: gemma-3-4b-it-qat-Q4_K_M.gguf
      temperature: 1.0
      top_k: 64
      top_p: 0.95
      min_p: 0.0
    context_size: 8192
    template:
      chat_message: |-
        <start_of_turn>{{if eq .RoleName \"assistant\" }}model{{else}}{{ .RoleName }}{{end}}
        {{ if .FunctionCall -}}
        {{ else if eq .RoleName \"tool\" -}}
        {{ end -}}
        {{ if .Content -}}
        {{.Content -}}
        {{ end -}}
        {{ if .FunctionCall -}}
        {{toJson .FunctionCall}}
        {{ end -}}<end_of_turn>
      chat: |
        {{.Input }}
        <start_of_turn>model
      completion: |
        {{.Input}}
      function: |
        <start_of_turn>system
        You have access to functions. If you decide to invoke any of the function(s),
        you MUST put it in the format of
        {\"name\": function name, \"parameters\": dictionary of argument name and its value}

        You SHOULD NOT include any other text in the response if you call a function
        {{range .Functions}}
        {'type': 'function', 'function': {'name': '{{.Name}}', 'description': '{{.Description}}', 'parameters': {{toJson .Parameters}} }}
        {{end}}
        <end_of_turn>
        {{.Input -}}
        <start_of_turn>model
    stopwords:
    - '<|im_end|>'
    - '<end_of_turn>'
    - '<start_of_turn>'
    f16: true
    mmap: true
