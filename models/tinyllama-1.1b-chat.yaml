#syntax=ghcr.io/sozercan/aikit:latest
apiVersion: v1alpha1
debug: true
models:
  - name: tinyllama-1.1b-chat
    source: https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf
    sha256: "9fecc3b3cd76bba89d504f29b616eedf7da85b96540e490ca5824d3f7d2776a0"
config: |
  - name: tinyllama-1.1b-chat
    backend: llama
    parameters:
      top_k: 80
      temperature: 0.2
      top_p: 0.7
      model: tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf
    context_size: 2048
