#syntax=ghcr.io/sozercan/aikit:latest
apiVersion: v1alpha1
debug: true
runtime: cuda
models:
  - name: phi-3.5-3.8b-instruct
    source: https://huggingface.co/MaziyarPanahi/Phi-3.5-mini-instruct-GGUF/resolve/main/Phi-3.5-mini-instruct.Q4_K_M.gguf
    sha256: 3f68916e850b107d8641d18bcd5548f0d66beef9e0a9077fe84ef28943eb7e88
    promptTemplates:
      - name: chatMsg
        template: |
          <|{{ .RoleName }}|>
          {{.Content}}<|end|>
      - name: chat
        template: |
          {{.Input}}
          <|assistant|>
      - name: completion
        template: |
          {{.Input}}
config: |
  - name: phi-3.5-3.8b-instruct
    backend: llama
    parameters:
      model: Phi-3.5-mini-instruct.Q4_K_M.gguf
    context_size: 4096
    template:
      chat_message: chatMsg
      chat: chat
      completion: completion
    stopwords:
    - <|user|>
    - <|assistant|>
    - <|end|>
    f16: true
    mmap: true
